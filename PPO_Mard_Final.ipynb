{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNg8AfBJ8ZXVSj9w2w1Zf8q",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ezzeddinegasmi/DRL_comparative_study/blob/main/PPO_Mard_Final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8cVuySv5jpKO",
        "outputId": "f1b51511-fc5d-4d54-ffff-c0d017e7809b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CartPole-v0\n",
            "CartPole-v1\n",
            "MountainCar-v0\n",
            "MountainCarContinuous-v0\n",
            "Pendulum-v1\n",
            "Acrobot-v1\n",
            "phys2d/CartPole-v0\n",
            "phys2d/CartPole-v1\n",
            "phys2d/Pendulum-v0\n",
            "LunarLander-v3\n",
            "LunarLanderContinuous-v3\n",
            "BipedalWalker-v3\n",
            "BipedalWalkerHardcore-v3\n",
            "CarRacing-v3\n",
            "Blackjack-v1\n",
            "FrozenLake-v1\n",
            "FrozenLake8x8-v1\n",
            "CliffWalking-v0\n",
            "Taxi-v3\n",
            "tabular/Blackjack-v0\n",
            "tabular/CliffWalking-v0\n",
            "Reacher-v2\n",
            "Reacher-v4\n",
            "Reacher-v5\n",
            "Pusher-v2\n",
            "Pusher-v4\n",
            "Pusher-v5\n",
            "InvertedPendulum-v2\n",
            "InvertedPendulum-v4\n",
            "InvertedPendulum-v5\n",
            "InvertedDoublePendulum-v2\n",
            "InvertedDoublePendulum-v4\n",
            "InvertedDoublePendulum-v5\n",
            "HalfCheetah-v2\n",
            "HalfCheetah-v3\n",
            "HalfCheetah-v4\n",
            "HalfCheetah-v5\n",
            "Hopper-v2\n",
            "Hopper-v3\n",
            "Hopper-v4\n",
            "Hopper-v5\n",
            "Swimmer-v2\n",
            "Swimmer-v3\n",
            "Swimmer-v4\n",
            "Swimmer-v5\n",
            "Walker2d-v2\n",
            "Walker2d-v3\n",
            "Walker2d-v4\n",
            "Walker2d-v5\n",
            "Ant-v2\n",
            "Ant-v3\n",
            "Ant-v4\n",
            "Ant-v5\n",
            "Humanoid-v2\n",
            "Humanoid-v3\n",
            "Humanoid-v4\n",
            "Humanoid-v5\n",
            "HumanoidStandup-v2\n",
            "HumanoidStandup-v4\n",
            "HumanoidStandup-v5\n",
            "GymV21Environment-v0\n",
            "GymV26Environment-v0\n"
          ]
        }
      ],
      "source": [
        "import gymnasium as gym\n",
        "for i in gym.envs.registry.keys():\n",
        "\tprint(i)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gymnasium as gym\n",
        "env = gym.make(\"CartPole-v1\")"
      ],
      "metadata": {
        "id": "zPBSF1vxkPXp"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"observation space: \", env.observation_space)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "84fFxqDdkhvp",
        "outputId": "df4191f9-867c-41d5-d02d-c4146b46d6b8"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "observation space:  Box([-4.8               -inf -0.41887903        -inf], [4.8               inf 0.41887903        inf], (4,), float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "observation space:  Box([-4.8 -inf -0.41887903 -inf], [4.8 inf 0.41887903 inf], (4,), float32)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "id": "3jSblT-ynh5U",
        "outputId": "0d1ecf4b-40f4-4b9d-8454-6e3150b6a824"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "invalid syntax (<ipython-input-30-b0f5ffecef64>, line 1)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-30-b0f5ffecef64>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    observation space:  Box([-4.8 -inf -0.41887903 -inf], [4.8 inf 0.41887903 inf], (4,), float32)\u001b[0m\n\u001b[0m                ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "observation, info = env.reset()\n",
        "print(\"observation: \", observation)"
      ],
      "metadata": {
        "id": "nW4FyIxjnqSy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "[ 0.03481963 -0.0277232   0.01703267 -0.04870504]"
      ],
      "metadata": {
        "id": "NuAFTdKyn0Oj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"action space: \", env.action_space)"
      ],
      "metadata": {
        "id": "8afGjL0un6Xj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "action space:  Discrete(2)"
      ],
      "metadata": {
        "id": "67UkKs-ioIOM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "env = gym.make('CartPole-v1')"
      ],
      "metadata": {
        "id": "xzBXYZVdoMhj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SEED = 1111\n",
        "env.reset(seed=SEED)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XOBmNRUnohYM",
        "outputId": "2c62e01b-2d8d-48e4-f2f2-57dd4336e672"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([ 0.03593444,  0.01567786, -0.00182151,  0.01612927], dtype=float32),\n",
              " {})"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158
        },
        "id": "G10r2yVoosfO",
        "outputId": "7200e782-d7f3-484c-e09a-aadd05dfc71d"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'np' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-32-67a86c8e2d2f>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSEED\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmanual_seed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSEED\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class PolicyNetwork(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, output_dim, dropout):\n",
        "        super().__init__()\n",
        "        self.layer1 = nn.Linear(input_dim, hidden_dim)\n",
        "        self.layer2 = nn.Linear(hidden_dim, output_dim)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "    def forward(self, x):\n",
        "        x = self.layer1(x)\n",
        "        x = self.dropout(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.layer2(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "BIMnpeLIoyKO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_stepwise_returns(rewards, discount_factor):\n",
        "    returns = []\n",
        "    R = 0\n",
        "    for r in reversed(rewards):\n",
        "        R = r + R * discount_factor\n",
        "        returns.insert(0, R)\n",
        "    returns = torch.tensor(returns)\n",
        "    normalized_returns = (returns - returns.mean()) / returns.std()\n",
        "    return normalized_returns\n",
        "\n"
      ],
      "metadata": {
        "id": "UuBEnwo5pLY4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ".step()"
      ],
      "metadata": {
        "id": "pEp5PckyowGk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def forward_pass(env, policy, discount_factor):\n",
        "    log_prob_actions = []\n",
        "    rewards = []\n",
        "    done = False\n",
        "    episode_return = 0\n",
        "    policy.train()\n",
        "    observation, info = env.reset()\n",
        "    while not done:\n",
        "        observation = torch.FloatTensor(observation).unsqueeze(0)\n",
        "        action_pred = policy(observation)\n",
        "        action_prob = F.softmax(action_pred, dim = -1)\n",
        "        dist = distributions.Categorical(action_prob)\n",
        "        action = dist.sample()\n",
        "        log_prob_action = dist.log_prob(action)\n",
        "        observation, reward, terminated, truncated, info = env.step(action.item())\n",
        "        done = terminated or truncated\n",
        "        log_prob_actions.append(log_prob_action)\n",
        "        rewards.append(reward)\n",
        "        episode_return += reward\n",
        "    log_prob_actions = torch.cat(log_prob_actions)\n",
        "    stepwise_returns = calculate_stepwise_returns(rewards, discount_factor)\n",
        "    return episode_return, stepwise_returns, log_prob_actions\n",
        "\n"
      ],
      "metadata": {
        "id": "NFLUv4kqqCAS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_loss(stepwise_returns, log_prob_actions):\n",
        "    loss = -(stepwise_returns * log_prob_actions).sum()\n",
        "    return loss"
      ],
      "metadata": {
        "id": "7RCb0Dq-qKlZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def update_policy(stepwise_returns, log_prob_actions, optimizer):\n",
        "    stepwise_returns = stepwise_returns.detach()\n",
        "    loss = calculate_loss(stepwise_returns, log_prob_actions)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    return loss.item()"
      ],
      "metadata": {
        "id": "FFKBxt5LqUNH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    MAX_EPOCHS = 500\n",
        "    DISCOUNT_FACTOR = 0.99\n",
        "    N_TRIALS = 25\n",
        "    REWARD_THRESHOLD = 475\n",
        "    PRINT_INTERVAL = 10\n",
        "    INPUT_DIM = env.observation_space.shape[0]\n",
        "    HIDDEN_DIM = 128\n",
        "    OUTPUT_DIM = env.action_space.n\n",
        "    DROPOUT = 0.5\n",
        "    episode_returns = []\n",
        "    policy = PolicyNetwork(INPUT_DIM, HIDDEN_DIM, OUTPUT_DIM, DROPOUT)\n",
        "    LEARNING_RATE = 0.01\n",
        "    optimizer = optim.Adam(policy.parameters(), lr = LEARNING_RATE)\n",
        "    for episode in range(1, MAX_EPOCHS+1):\n",
        "        episode_return, stepwise_returns, log_prob_actions = forward_pass(env, policy, DISCOUNT_FACTOR)\n",
        "        _ = update_policy(stepwise_returns, log_prob_actions, optimizer)\n",
        "        episode_returns.append(episode_return)\n",
        "        mean_episode_return = np.mean(episode_returns[-N_TRIALS:])\n",
        "        if episode % PRINT_INTERVAL == 0:\n",
        "            print(f'| Episode: {episode:3} | Mean Rewards: {mean_episode_return:5.1f} |')\n",
        "        if mean_episode_return >= REWARD_THRESHOLD:\n",
        "            print(f'Reached reward threshold in {episode} episodes')\n",
        "            break\n",
        "\n"
      ],
      "metadata": {
        "id": "B7uJF2AjqYBp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "env = gym.make(‘CartPole-v1’, render_mode=’human’)"
      ],
      "metadata": {
        "id": "3RhPYl3gs85p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "while not done:\n",
        "    …\n",
        "   step, reward, terminated, truncated, info = env.step(action.item())\n",
        "   env.render()"
      ],
      "metadata": {
        "id": "nUvv4xiQtFO7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Hkdu4FBgtOpL"
      },
      "execution_count": 32,
      "outputs": []
    }
  ]
}