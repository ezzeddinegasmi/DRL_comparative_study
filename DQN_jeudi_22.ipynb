{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOQw+GVrxf73DXDNFVIFXnG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ezzeddinegasmi/DRL_comparative_study/blob/main/DQN_jeudi_22.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ksYeW8ZVw7IS",
        "outputId": "a9aca1cc-f70e-4835-c872-aaba21425bd9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.21.0+cu124)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (4.11.0.86)\n",
            "Requirement already satisfied: gym[atari] in /usr/local/lib/python3.11/dist-packages (0.26.2)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from gym[atari]) (3.1.1)\n",
            "Requirement already satisfied: gym_notices>=0.0.4 in /usr/local/lib/python3.11/dist-packages (from gym[atari]) (0.0.8)\n",
            "Requirement already satisfied: ale-py~=0.8.0 in /usr/local/lib/python3.11/dist-packages (from gym[atari]) (0.8.1)\n",
            "Requirement already satisfied: autorom~=0.4.2 in /usr/local/lib/python3.11/dist-packages (from autorom[accept-rom-license]~=0.4.2; extra == \"accept-rom-license\"->gym[accept-rom-license]) (0.4.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.1.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.11/dist-packages (from ale-py~=0.8.0->gym[atari]) (6.5.2)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from autorom~=0.4.2->autorom[accept-rom-license]~=0.4.2; extra == \"accept-rom-license\"->gym[accept-rom-license]) (8.1.8)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from autorom~=0.4.2->autorom[accept-rom-license]~=0.4.2; extra == \"accept-rom-license\"->gym[accept-rom-license]) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from autorom~=0.4.2->autorom[accept-rom-license]~=0.4.2; extra == \"accept-rom-license\"->gym[accept-rom-license]) (4.67.1)\n",
            "Requirement already satisfied: AutoROM.accept-rom-license in /usr/local/lib/python3.11/dist-packages (from autorom[accept-rom-license]~=0.4.2; extra == \"accept-rom-license\"->gym[accept-rom-license]) (0.6.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->autorom~=0.4.2->autorom[accept-rom-license]~=0.4.2; extra == \"accept-rom-license\"->gym[accept-rom-license]) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->autorom~=0.4.2->autorom[accept-rom-license]~=0.4.2; extra == \"accept-rom-license\"->gym[accept-rom-license]) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->autorom~=0.4.2->autorom[accept-rom-license]~=0.4.2; extra == \"accept-rom-license\"->gym[accept-rom-license]) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->autorom~=0.4.2->autorom[accept-rom-license]~=0.4.2; extra == \"accept-rom-license\"->gym[accept-rom-license]) (2025.1.31)\n"
          ]
        }
      ],
      "source": [
        "pip install gym[atari] gym[accept-rom-license] torch torchvision numpy matplotlib opencv-python"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gym\n",
        "import numpy as np\n",
        "import cv2\n",
        "\n",
        "def preprocess_frame(frame):\n",
        "    gray = cv2.cvtColor(frame, cv2.COLOR_RGB2GRAY)\n",
        "    resized = cv2.resize(gray, (84, 84), interpolation=cv2.INTER_AREA)\n",
        "    return resized / 255.0  # Normaliser\n",
        "\n",
        "def stack_frames(frames, new_frame, is_new_episode):\n",
        "    if is_new_episode:\n",
        "        frames = [new_frame] * 4\n",
        "    else:\n",
        "        frames.append(new_frame)\n",
        "        frames.pop(0)\n",
        "    return np.stack(frames, axis=0), frames\n"
      ],
      "metadata": {
        "id": "g4Sh_OtzxWI9"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class DQN(nn.Module):\n",
        "    def __init__(self, action_space):\n",
        "        super(DQN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(4, 32, 8, stride=4)\n",
        "        self.conv2 = nn.Conv2d(32, 64, 4, stride=2)\n",
        "        self.conv3 = nn.Conv2d(64, 64, 3, stride=1)\n",
        "        self.fc1 = nn.Linear(7*7*64, 512)\n",
        "        self.out = nn.Linear(512, action_space)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = F.relu(self.conv3(x))\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        return self.out(x)\n"
      ],
      "metadata": {
        "id": "YuJB2YZlx6Jl"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gym\n",
        "import numpy as np\n",
        "import cv2\n",
        "import random\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from collections import deque\n",
        "\n",
        "# --- Prétraitement de l'image ---\n",
        "def preprocess_frame(frame):\n",
        "    gray = cv2.cvtColor(frame, cv2.COLOR_RGB2GRAY)\n",
        "    resized = cv2.resize(gray, (84, 84), interpolation=cv2.INTER_AREA)\n",
        "    return resized / 255.0\n",
        "\n",
        "def stack_frames(frames, new_frame, is_new_episode):\n",
        "    if is_new_episode:\n",
        "        frames = [new_frame] * 4\n",
        "    else:\n",
        "        frames.append(new_frame)\n",
        "        frames.pop(0)\n",
        "    return np.stack(frames, axis=0), frames\n",
        "\n",
        "# --- Modèle DQN ---\n",
        "class DQN(nn.Module):\n",
        "    def __init__(self, action_space):\n",
        "        super(DQN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(4, 32, 8, stride=4)\n",
        "        self.conv2 = nn.Conv2d(32, 64, 4, stride=2)\n",
        "        self.conv3 = nn.Conv2d(64, 64, 3, stride=1)\n",
        "        self.fc1 = nn.Linear(7*7*64, 512)\n",
        "        self.out = nn.Linear(512, action_space)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.relu(self.conv1(x))\n",
        "        x = torch.relu(self.conv2(x))\n",
        "        x = torch.relu(self.conv3(x))\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        return self.out(x)\n",
        "\n",
        "# --- Replay Memory ---\n",
        "class ReplayBuffer:\n",
        "    def __init__(self, capacity):\n",
        "        self.buffer = deque(maxlen=capacity)\n",
        "\n",
        "    def push(self, state, action, reward, next_state, done):\n",
        "        self.buffer.append((state, action, reward, next_state, done))\n",
        "\n",
        "    def sample(self, batch_size):\n",
        "        batch = random.sample(self.buffer, batch_size)\n",
        "        states, actions, rewards, next_states, dones = zip(*batch)\n",
        "        return np.stack(states), actions, rewards, np.stack(next_states), dones\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.buffer)\n",
        "\n",
        "# --- Hyperparamètres ---\n",
        "EPISODES = 500\n",
        "BATCH_SIZE = 32\n",
        "GAMMA = 0.99\n",
        "EPS_START = 1.0\n",
        "EPS_END = 0.1\n",
        "EPS_DECAY = 1000000\n",
        "TARGET_UPDATE = 1000\n",
        "REPLAY_SIZE = 100000\n",
        "LEARNING_RATE = 0.00025\n",
        "\n",
        "# --- Initialisation ---\n",
        "env = gym.make(\"ALE/Breakout-v5\", render_mode=None)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "main_dqn = DQN(env.action_space.n).to(device)\n",
        "target_dqn = DQN(env.action_space.n).to(device)\n",
        "target_dqn.load_state_dict(main_dqn.state_dict())\n",
        "\n",
        "optimizer = optim.Adam(main_dqn.parameters(), lr=LEARNING_RATE)\n",
        "memory = ReplayBuffer(REPLAY_SIZE)\n",
        "steps_done = 0\n",
        "\n",
        "# --- Choix d'action ε-greedy ---\n",
        "def select_action(state, epsilon):\n",
        "    if random.random() < epsilon:\n",
        "        return env.action_space.sample()\n",
        "    with torch.no_grad():\n",
        "        state = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(device)\n",
        "        q_values = main_dqn(state)\n",
        "        return q_values.argmax().item()\n",
        "\n",
        "# --- Entraînement principal ---\n",
        "for episode in range(EPISODES):\n",
        "    obs, _ = env.reset()\n",
        "    frame = preprocess_frame(obs)\n",
        "    state_stack = [frame] * 4\n",
        "    state = np.stack(state_stack, axis=0)\n",
        "    total_reward = 0\n",
        "    done = False\n",
        "\n",
        "    while not done:\n",
        "        epsilon = EPS_END + (EPS_START - EPS_END) * np.exp(-1. * steps_done / EPS_DECAY)\n",
        "        action = select_action(state, epsilon)\n",
        "        next_obs, reward, terminated, truncated, _ = env.step(action)\n",
        "        done = terminated or truncated\n",
        "\n",
        "        next_frame = preprocess_frame(next_obs)\n",
        "        next_state, state_stack = stack_frames(state_stack, next_frame, is_new_episode=False)\n",
        "        memory.push(state, action, reward, next_state, done)\n",
        "\n",
        "        state = next_state\n",
        "        total_reward += reward\n",
        "        steps_done += 1\n",
        "\n",
        "        # Apprentissage\n",
        "        if len(memory) > BATCH_SIZE:\n",
        "            states, actions, rewards, next_states, dones = memory.sample(BATCH_SIZE)\n",
        "            states = torch.tensor(states, dtype=torch.float32).to(device)\n",
        "            actions = torch.tensor(actions).to(device)\n",
        "            rewards = torch.tensor(rewards).to(device)\n",
        "            next_states = torch.tensor(next_states, dtype=torch.float32).to(device)\n",
        "            dones = torch.tensor(dones).to(device)\n",
        "\n",
        "            q_values = main_dqn(states).gather(1, actions.unsqueeze(1)).squeeze(1)\n",
        "            next_q_values = target_dqn(next_states).max(1)[0]\n",
        "            expected_q = rewards + GAMMA * next_q_values * (1 - dones)\n",
        "\n",
        "            loss = nn.MSELoss()(q_values, expected_q.detach())\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        # Mise à jour du réseau cible\n",
        "        if steps_done % TARGET_UPDATE == 0:\n",
        "            target_dqn.load_state_dict(main_dqn.state_dict())\n",
        "\n",
        "    print(f\"Épisode {episode + 1} - Récompense: {total_reward:.0f} - Epsilon: {epsilon:.3f}\")\n",
        "\n",
        "env.close()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "3MWsECHzyiqK",
        "outputId": "f80249d2-0a9b-4b62-bcfe-7e3bf4dbddaa"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "module 'numpy' has no attribute 'bool8'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-87-308223166305>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    100\u001b[0m         \u001b[0mepsilon\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEPS_END\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mEPS_START\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mEPS_END\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1.\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0msteps_done\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mEPS_DECAY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselect_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m         \u001b[0mnext_obs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mterminated\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtruncated\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m         \u001b[0mdone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mterminated\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mtruncated\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/gym/wrappers/order_enforcing.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_has_reset\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mResetNeeded\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Cannot call env.step() before calling env.reset()\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/gym/wrappers/env_checker.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchecked_step\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchecked_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0menv_step_passive_checker\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/gym/utils/passive_env_checker.py\u001b[0m in \u001b[0;36menv_step_passive_checker\u001b[0;34m(env, action)\u001b[0m\n\u001b[1;32m    231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m         \u001b[0;31m# np.bool is actual python bool not np boolean type, therefore bool_ or bool8\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 233\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mterminated\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbool8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    234\u001b[0m             logger.warn(\n\u001b[1;32m    235\u001b[0m                 \u001b[0;34mf\"Expects `terminated` signal to be a boolean, actual type: {type(terminated)}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/numpy/__init__.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(attr)\u001b[0m\n\u001b[1;32m    408\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mchar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchararray\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 410\u001b[0;31m         raise AttributeError(\"module {!r} has no attribute \"\n\u001b[0m\u001b[1;32m    411\u001b[0m                              \"{!r}\".format(__name__, attr))\n\u001b[1;32m    412\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: module 'numpy' has no attribute 'bool8'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "t-eaRNPA17iv"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(main_dqn.state_dict(), \"breakout_dqn.pt\")"
      ],
      "metadata": {
        "id": "TR3vK3jozJ3M"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gym\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import cv2\n",
        "import time\n",
        "\n",
        "# --- Même réseau que pour l'entraînement ---\n",
        "class DQN(nn.Module):\n",
        "    def __init__(self, action_space):\n",
        "        super(DQN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(4, 32, 8, stride=4)\n",
        "        self.conv2 = nn.Conv2d(32, 64, 4, stride=2)\n",
        "        self.conv3 = nn.Conv2d(64, 64, 3, stride=1)\n",
        "        self.fc1 = nn.Linear(7*7*64, 512)\n",
        "        self.out = nn.Linear(512, action_space)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.relu(self.conv1(x))\n",
        "        x = torch.relu(self.conv2(x))\n",
        "        x = torch.relu(self.conv3(x))\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        return self.out(x)\n",
        "\n",
        "# --- Prétraitement comme avant ---\n",
        "def preprocess_frame(frame):\n",
        "    gray = cv2.cvtColor(frame, cv2.COLOR_RGB2GRAY)\n",
        "    resized = cv2.resize(gray, (84, 84), interpolation=cv2.INTER_AREA)\n",
        "    return resized / 255.0\n",
        "\n",
        "def stack_frames(frames, new_frame, is_new_episode):\n",
        "    if is_new_episode:\n",
        "        frames = [new_frame] * 4\n",
        "    else:\n",
        "        frames.append(new_frame)\n",
        "        frames.pop(0)\n",
        "    return np.stack(frames, axis=0), frames\n",
        "\n",
        "# --- Setup ---\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "env = gym.make(\"ALE/Breakout-v5\", render_mode=\"human\")\n",
        "\n",
        "model = DQN(env.action_space.n).to(device)\n",
        "model.load_state_dict(torch.load(\"breakout_dqn.pt\", map_location=device))\n",
        "model.eval()\n",
        "\n",
        "# --- Exécution du modèle ---\n",
        "obs, _ = env.reset()\n",
        "frame = preprocess_frame(obs)\n",
        "state_stack = [frame] * 4\n",
        "state = np.stack(state_stack, axis=0)\n",
        "\n",
        "done = False\n",
        "total_reward = 0\n",
        "\n",
        "while not done:\n",
        "    with torch.no_grad():\n",
        "        state_tensor = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(device)\n",
        "        q_values = model(state_tensor)\n",
        "        action = q_values.argmax().item()\n",
        "\n",
        "    obs, reward, terminated, truncated, _ = env.step(action)\n",
        "    done = terminated or truncated\n",
        "    total_reward += reward\n",
        "\n",
        "    next_frame = preprocess_frame(obs)\n",
        "    state, state_stack = stack_frames(state_stack, next_frame, is_new_episode=False)\n",
        "\n",
        "    time.sleep(0.02)  # Pour ralentir un peu le jeu\n",
        "\n",
        "print(f\"Score total : {total_reward}\")\n",
        "env.close()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "xsaoKpo20K9H",
        "outputId": "bd03fbda-c551-4454-d3b0-94e748fbb39b"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "Failed to initialize SDL",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-89-67d067b6c368>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;31m# --- Setup ---\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cuda\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m \u001b[0menv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgym\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ALE/Breakout-v5\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrender_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"human\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDQN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction_space\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/gym/envs/registration.py\u001b[0m in \u001b[0;36mmake\u001b[0;34m(id, max_episode_steps, autoreset, apply_api_compatibility, disable_env_checker, **kwargs)\u001b[0m\n\u001b[1;32m    638\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    639\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 640\u001b[0;31m         \u001b[0menv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv_creator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0m_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    641\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    642\u001b[0m         if (\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ale_py/env/gym.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, game, mode, difficulty, obs_type, frameskip, repeat_action_probability, full_action_space, max_num_frames_per_episode, render_mode)\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m         \u001b[0;31m# Seed + Load\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 155\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    156\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m         self._action_set = (\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ale_py/env/gym.py\u001b[0m in \u001b[0;36mseed\u001b[0;34m(self, seed)\u001b[0m\n\u001b[1;32m    213\u001b[0m                 \u001b[0;34m\"https://github.com/mgbellemare/Arcade-Learning-Environment#rom-management\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m             )\n\u001b[0;32m--> 215\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0male\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloadROM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_game\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    216\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_game_mode\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Failed to initialize SDL"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "obs, _ = env.reset()\n",
        "frame = preprocess_frame(obs)\n",
        "state_stack = [frame] * 4\n",
        "state = np.stack(state_stack, axis=0)\n",
        "\n",
        "# --- Appuyer sur \"FIRE\" pour commencer le jeu ---\n",
        "obs, reward, terminated, truncated, _ = env.step(1)  # action FIRE"
      ],
      "metadata": {
        "id": "BzyPKtwh1-yv"
      },
      "execution_count": 71,
      "outputs": []
    }
  ]
}